{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbef8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=\"your_api_key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5662454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1fcc4dc74f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import pandas as pd\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "# Loading dataset\n",
    "data = pd.read_csv(\"salaries.csv\")\n",
    "\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Layout of the app\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"Kaggle Data Insights with LLM\"),\n",
    "    html.Div(\"Ask anything about the Kaggle data!\"),\n",
    "    dcc.Textarea(id=\"user-input\", placeholder=\"Ask a question about the data...\", style={'width': '100%', 'height': 100}),\n",
    "    html.Button('Submit', id='submit-button', n_clicks=0),\n",
    "    html.Div(id='response-output', style={'whiteSpace': 'pre-line'})\n",
    "])\n",
    "\n",
    "# Function to send a query to Groq LLM using Groq library\n",
    "def query_groq_llm(prompt):\n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=\"llama3-8b-8192\",  # This is an example model name. Modify it as per the model you want to use.\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "\n",
    "# Callback to handle user input and generate LLM response\n",
    "@app.callback(\n",
    "    Output('response-output', 'children'),\n",
    "    Input('submit-button', 'n_clicks'),\n",
    "    State('user-input', 'value')\n",
    ")\n",
    "def generate_response(n_clicks, user_input):\n",
    "    if n_clicks > 0 and user_input:\n",
    "        # Query Groq LLM API\n",
    "        prompt = f\"Using the following data:\\n{data.head().to_string()}\\nAnswer the following question: {user_input}\"\n",
    "        response = query_groq_llm(prompt)\n",
    "        return response\n",
    "    return \"\"\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2213f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
